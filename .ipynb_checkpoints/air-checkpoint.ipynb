{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data : (9151, 8)\n",
      "Shape of training data after dropping : (6624, 8)\n"
     ]
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('./datasets/Data Sheet - Buvana - Trial 1.csv')\n",
    "#test_data = pd.read_csv('test_data.csv')\n",
    " \n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "# print('Shape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n",
    "train_data=train_data.dropna(subset=['TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602', 'Temperature', 'Humidity', 'Class']) #ID removed later causing disturbances in predictions as it is of no use for predictions\n",
    "print('Shape of training data after dropping :',train_data.shape)\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Class', 'Temperature', 'Humidity', 'ID'],axis=1) # added to drop , 'Temperature', 'Humidity', 'ID' in from v2\n",
    "train_y = train_data['Class']\n",
    " \n",
    "# seperate the independent and target variable on testing data\n",
    "# test_x = test_data.drop(columns=['Class'],axis=1)\n",
    "# test_y = test_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''preprocessed data dumping'''\n",
    "    dtime=str(datetime.datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")).replace(\" \", \"_\")\n",
    "    #os.mkdir(\"logs\")#path = os.path.join(parent_dir, directory), os.mkdir(path, mode) \n",
    "    #'''\n",
    "    try: #if already exist then exception raise(can be done with conditions(if..else) check already present, if not create or using try..catch block)\n",
    "        os.mkdir(\"preprocessed\") #path\n",
    "    except OSError as error: \n",
    "        print(error)  \n",
    "    #'''\n",
    "    filename=f\"./preprocessed/training_data_preprocessed_{dtime}.csv\"#str()#.\\logs\\ # log files also can be added to input entries\n",
    "    #print(filename)\n",
    "    #print(type(filename))\n",
    "    #train_data.to_csv(str(filename))\n",
    "    train_data.to_csv(str(filename),mode = 'w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TGS 826</th>\n",
       "      <th>TGS 822</th>\n",
       "      <th>TGS 2600</th>\n",
       "      <th>TGS 2602</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9147</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6344 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TGS 826  TGS 822  TGS 2600  TGS 2602\n",
       "403      0.04     1.34      0.77      2.61\n",
       "404      0.04     1.38      0.85      2.66\n",
       "405      0.04     1.38      0.94      2.68\n",
       "406      0.04     1.35      1.05      2.78\n",
       "407      0.04     1.30      1.16      2.95\n",
       "...       ...      ...       ...       ...\n",
       "9146     0.04     0.17      0.20      0.16\n",
       "9147     0.04     0.17      0.20      0.16\n",
       "9148     0.04     0.17      0.20      0.17\n",
       "9149     0.04     0.17      0.20      0.17\n",
       "9150     0.04     0.17      0.20      0.17\n",
       "\n",
       "[6344 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[280:]\n",
    "# train_data[280:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Acetone 1 ppm\n",
       "1      Acetone 1 ppm\n",
       "2      Acetone 1 ppm\n",
       "3      Acetone 1 ppm\n",
       "4      Acetone 1 ppm\n",
       "           ...      \n",
       "399    Acetone 2 ppm\n",
       "400    Acetone 2 ppm\n",
       "401    Acetone 2 ppm\n",
       "402    Acetone 2 ppm\n",
       "403    Acetone 2 ppm\n",
       "Name: Class, Length: 281, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:281]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TGS 826</th>\n",
       "      <th>TGS 822</th>\n",
       "      <th>TGS 2600</th>\n",
       "      <th>TGS 2602</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9147</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6344 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TGS 826  TGS 822  TGS 2600  TGS 2602\n",
       "403      0.04     1.34      0.77      2.61\n",
       "404      0.04     1.38      0.85      2.66\n",
       "405      0.04     1.38      0.94      2.68\n",
       "406      0.04     1.35      1.05      2.78\n",
       "407      0.04     1.30      1.16      2.95\n",
       "...       ...      ...       ...       ...\n",
       "9146     0.04     0.17      0.20      0.16\n",
       "9147     0.04     0.17      0.20      0.16\n",
       "9148     0.04     0.17      0.20      0.17\n",
       "9149     0.04     0.17      0.20      0.17\n",
       "9150     0.04     0.17      0.20      0.17\n",
       "\n",
       "[6344 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_x.dropna(how='all')\n",
    "train_x=train_x.fillna(0)\n",
    "train_x[280:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rohit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Target on train data ['Acetone 1 ppm' 'Acetone 1 ppm' 'Acetone 1 ppm' ... 'Ammonia 5 ppm'\n",
      " 'Ammonia 5 ppm' 'Ammonia 5 ppm']\n",
      "\n",
      "accuracy_score on train dataset :  0.9968297101449275\n",
      "    ID  TGS 826  TGS 822  TGS 2600  TGS 2602  Temperature  Humidity\n",
      "0  0.0     0.04     0.19       0.2      0.17         37.0      40.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602'] ['ID', 'TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602', 'Temperature', 'Humidity']\ntraining data did not have the following fields: Temperature, ID, Humidity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f5b868ca883e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TGS 826\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TGS 822\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TGS 2600\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TGS 2602\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Temperature\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Humidity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mpredict_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;31m# print('\\nTarget on test data',predict_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rohit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m             validate_features=validate_features)\n\u001b[0m\u001b[0;32m    975\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rohit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[0;32m   1483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rohit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 2061\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   2062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m     def get_split_value_histogram(self, feature, fmap='', bins=None,\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602'] ['ID', 'TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602', 'Temperature', 'Humidity']\ntraining data did not have the following fields: Temperature, ID, Humidity"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    " \n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    " \n",
    " \n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('\\nTarget on train data',predict_train) \n",
    " \n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(train_y,predict_train)\n",
    "print('\\naccuracy_score on train dataset : ', accuracy_train)\n",
    " \n",
    "# # predict the target on the test dataset\n",
    "test_x=np.array([[0,0.04,0.19,0.2,0.17,37,40]])\n",
    "df_test = pd.DataFrame(data=test_x, index=[0], columns=[\"ID\", \"TGS 826\", \"TGS 822\", \"TGS 2600\", \"TGS 2602\", \"Temperature\", \"Humidity\"])\n",
    "print(df_test)\n",
    "predict_test = model.predict(df_test)\n",
    "# print('\\nTarget on test data',predict_test)\n",
    "\n",
    "predict_test = model.predict(train_x)\n",
    "print('\\nTarget on test data',predict_test)\n",
    "print(type(predict_test))\n",
    "# convert n_array into dataframe\n",
    "DF = pd.DataFrame(predict_test)\n",
    "dtime=str(datetime.datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")).replace(\" \", \"_\")\n",
    "filename=f\"testing_data_logs_{dtime}.csv\"#str()\n",
    "#print(filename)\n",
    "#print(type(filename))\n",
    "DF.to_csv(str(filename))\n",
    "# Accuracy Score on test dataset\n",
    "# accuracy_test = accuracy_score(test_y,predict_test)\n",
    "# print('\\naccuracy_score on test dataset : ', accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data.drop(columns=['Class','ID'],axis=1)\n",
    "train_y = train_data['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3974, 6) (2650, 6) (3974,) (2650,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rohit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Target on train data ['Ethanol 4 ppm' 'Ethanol 5 ppm' 'Ammonia 2 ppm' ... 'Ethanol 1 ppm'\n",
      " 'Ethanol 3 ppm' 'Ethanol 3 ppm']\n",
      "\n",
      "accuracy_score on train dataset :  1.0\n",
      "\n",
      "Target on test data ['Ethanol 5 ppm' 'Ethanol 5 ppm' 'Acetone 5 ppm' ... 'Ammonia 5 ppm'\n",
      " 'Ethanol 3 ppm' 'Ethanol 3 ppm']\n",
      "\n",
      "accuracy_score on test dataset :  0.9996226415094339\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    " \n",
    "# fit the model with the training data\n",
    "model.fit(X_train,y_train)\n",
    " \n",
    " \n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(X_train)\n",
    "print('\\nTarget on train data',predict_train) \n",
    " \n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(y_train,predict_train)\n",
    "print('\\naccuracy_score on train dataset : ', accuracy_train)\n",
    " \n",
    "# # predict the target on the test dataset\n",
    "predict_test = model.predict(X_test)\n",
    "print('\\nTarget on test data',predict_test)\n",
    "\n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(y_test,predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Predictions through input entries\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602', 'Temperature', 'Humidity'] ['ID', 'TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602', 'Temperature', 'Humidity']\ntraining data did not have the following fields: ID",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3f88a3d400d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TGS 826\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TGS 822\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TGS 2600\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TGS 2602\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Temperature\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Humidity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#print(df_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mpredict_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#print('\\nTarget on test data',predict_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rohit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m             validate_features=validate_features)\n\u001b[0m\u001b[0;32m    975\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rohit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[0;32m   1483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rohit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 2061\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   2062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m     def get_split_value_histogram(self, feature, fmap='', bins=None,\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602', 'Temperature', 'Humidity'] ['ID', 'TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602', 'Temperature', 'Humidity']\ntraining data did not have the following fields: ID"
     ]
    }
   ],
   "source": [
    "#version2.0\n",
    "\n",
    "model = XGBClassifier()\n",
    " \n",
    "# fit the model with the training data\n",
    "model.fit(X_train,y_train)\n",
    "print(\"Predictions through input entries\")\n",
    "test_x=np.array([[0,0.04,0.19,0.2,0.17,37,40]]) #['Target on test data: Acetone 1 ppm\\n [Logs]: ']\n",
    "#test_x=np.array([[0,float(e0.get()),float(e1.get()),float(e2.get()),float(e3.get()),float(e4.get()),float(e5.get())]])\n",
    "df_test = pd.DataFrame(data=test_x, index=[0], columns=[\"ID\", \"TGS 826\", \"TGS 822\", \"TGS 2600\", \"TGS 2602\", \"Temperature\", \"Humidity\"])\n",
    "#print(df_test)\n",
    "predict_test = model.predict(df_test)\n",
    "#print('\\nTarget on test data',predict_test)\n",
    "p2=model.predict_proba(df_test)\n",
    "#print('\\nTarget on test data(p2)',p2)\n",
    "#print(p2[0])\n",
    "#print(p2[0][0])\n",
    "# print(p2[0].argmax())\n",
    "probs=p2[0]\n",
    "print(probs)\n",
    "#first=p2[0].argmax()\n",
    "first=probs.argmax()\n",
    "probs=np.delete(probs, first)\n",
    "second=probs.argmax()\n",
    "print(first, second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_data['Class']\n",
    "classes[0]\n",
    "print(type(classes[0]))\n",
    "print(classes)\n",
    "#classes=classes.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "classes=classes.drop_duplicates(keep='first', inplace=False)\n",
    "'''# sorting by first name\n",
    "data.sort_values(\"First Name\", inplace = True)'''\n",
    "classes\n",
    "len(classes)\n",
    "# classes[2]\n",
    "classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.iloc[1]\n",
    "#classes.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Target on test data ['Ammonia 5 ppm']\n",
      "\n",
      "Target on test data(p2) [[5.5765035e-04 6.6059688e-04 3.4352174e-04 1.9731064e-04 2.8564551e-04\n",
      "  2.3162234e-04 3.0786321e-03 2.8039591e-04 3.9736772e-04 9.9149901e-01\n",
      "  5.2002724e-04 3.4739194e-04 2.8905395e-04 2.8499137e-04 1.0267867e-03]]\n",
      "[1.9731064e-04 2.3162234e-04 2.8039591e-04 2.8499137e-04 2.8564551e-04\n",
      " 2.8905395e-04 3.4352174e-04 3.4739194e-04 3.9736772e-04 5.2002724e-04\n",
      " 5.5765035e-04 6.6059688e-04 1.0267867e-03 3.0786321e-03 9.9149901e-01]\n",
      "9 6\n",
      "0       Acetone 1 ppm\n",
      "281     Acetone 2 ppm\n",
      "596     Acetone 3 ppm\n",
      "926     Acetone 4 ppm\n",
      "1379    Acetone 5 ppm\n",
      "2067    Ethanol 1 ppm\n",
      "2710    Ethanol 2 ppm\n",
      "3473    Ethanol 3 ppm\n",
      "4810    Ethanol 4 ppm\n",
      "5242    Ethanol 5 ppm\n",
      "6067    Ammonia 1 ppm\n",
      "6594    Ammonia 2 ppm\n",
      "6946    Ammonia 3 ppm\n",
      "7656    Ammonia 4 ppm\n",
      "8669    Ammonia 5 ppm\n",
      "Name: Class, dtype: object\n",
      "Ethanol 5 ppm\n",
      "9 6\n",
      "Ethanol 5 ppm\n"
     ]
    }
   ],
   "source": [
    "#version2.0\n",
    "\n",
    "model = XGBClassifier()\n",
    " \n",
    "# fit the model with the training data\n",
    "model.fit(X_train,y_train)\n",
    "#print(\"Predictions through input entries\")\n",
    "# test_x=np.array([[0.04,0.19,0.2,0.17,37,40]]) #['Target on test data: Acetone 1 ppm\\n [Logs]: ']\n",
    "test_x=np.array([[0.04,0.17,0.2,0.17,37,39]]) #['Target on test data: Acetone 1 ppm\\n [Logs]: ']\n",
    "#test_x=np.array([[0,float(e0.get()),float(e1.get()),float(e2.get()),float(e3.get()),float(e4.get()),float(e5.get())]])\n",
    "df_test = pd.DataFrame(data=test_x, index=[0], columns=[\"TGS 826\", \"TGS 822\", \"TGS 2600\", \"TGS 2602\", \"Temperature\", \"Humidity\"])\n",
    "#print(df_test)\n",
    "predict_test = model.predict(df_test)\n",
    "print('\\nTarget on test data',predict_test)\n",
    "p2=model.predict_proba(df_test)\n",
    "print('\\nTarget on test data(p2)',p2)\n",
    "#print(p2[0])\n",
    "#print(p2[0][0])\n",
    "# print(p2[0].argmax())\n",
    "probs=p2[0]\n",
    "#print(probs)\n",
    "#first=p2[0].argmax()\n",
    "print(np.sort(probs))\n",
    "first=probs.argmax()#argmin()\n",
    "# probs=np.delete(probs, first)\n",
    "probs[first]=-100e-10\n",
    "second=probs.argmax()#argmin()\n",
    "print(first, second)\n",
    "\n",
    "'''class_dict={\n",
    "    0: \"Acetone 1 ppm\",\n",
    "    1: \"Acetone 1 ppm\"\n",
    "}....'''\n",
    "classes = train_data['Class']\n",
    "classes=classes.drop_duplicates(keep='first', inplace=False)\n",
    "print(classes)\n",
    "print(classes.iloc[first])\n",
    "print(first, second)\n",
    "if first+1 == second:\n",
    "    range_res=f'{classes.iloc[first]} to {classes.iloc[second]}'\n",
    "else:\n",
    "    range_res=f'{classes.iloc[first]}'\n",
    "\n",
    "print(range_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions through CSV file\n",
      "Shape of testing data after dropping : (6624, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Predictions through CSV file\")\n",
    "# print(label_file_explorer.cget(\"text\"))\n",
    "test_data = pd.read_csv('R:/airprob/datasets/Data Sheet - Buvana - Trial 1.csv')\n",
    "test_data=test_data.dropna(subset=['TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602', 'Temperature', 'Humidity', 'Class'])\n",
    "print('Shape of testing data after dropping :',train_data.shape)\n",
    "# seperate the independent and target variable on training data\n",
    "test_data_x = test_data.drop(columns=['Class', 'ID'],axis=1)\n",
    "test_data_y = test_data['Class']\n",
    "predict_test = model.predict(test_data_x)\n",
    "#print('\\nTarget on test data',predict_test)\n",
    "p2=model.predict_proba(test_data_x)#version2 needs conf,probs of each class(out of 15) to the input features,args and present range(highest,second highest)\n",
    "#print('\\nTarget on test data(p2)',p2)\n",
    "output= \" \\n \" + \"[Logs]: \" + 'Target on test data: '+ predict_test + \" \\n \"\n",
    "#print(type(predict_test))\n",
    "# convert n_array into dataframe\n",
    "DF = pd.DataFrame(predict_test)\n",
    "#len(predict_test)\n",
    "\n",
    "res=[]\n",
    "for i in p2:\n",
    "    #print(i)\n",
    "    probs=i\n",
    "    #print(probs)\n",
    "    #first=p2[0].argmax()\n",
    "    first=probs.argmax()#argmin()\n",
    "    # probs=np.delete(probs, first)\n",
    "    probs[first]=-100\n",
    "    second=probs.argmax()#argmin()\n",
    "    #print(first, second)\n",
    "    '''class_dict={\n",
    "        0: \"Acetone 1 ppm\",\n",
    "        1: \"Acetone 1 ppm\"\n",
    "    }....'''\n",
    "    classes = train_data['Class']\n",
    "    classes=classes.drop_duplicates(keep='first', inplace=False)\n",
    "    #print(classes.iloc[first])\n",
    "    if first+1 == second:\n",
    "            range_res=f'{classes.iloc[first]} to {classes.iloc[second]}'\n",
    "    else:\n",
    "            range_res=f'{classes.iloc[first]}'\n",
    "    res.append(range_res)\n",
    "    #print(type(range_res))\n",
    "#print(len(res))\n",
    "#print(len(predict_test))\n",
    "n_res=np.array(res)\n",
    "type(n_res)\n",
    "#type(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Predictions through input entries\n",
      "\n",
      "Target on test data ['Ammonia 5 ppm']\n"
     ]
    }
   ],
   "source": [
    "#version2.0\n",
    "\n",
    "model = XGBClassifier()\n",
    " \n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "print(\"Predictions through input entries\")\n",
    "test_x=np.array([[0.04,0.17,0.2,0.17,37,39]]) #['Target on test data: Ammonia 5 ppm\\n [Logs]: ']\n",
    "# test_x=np.array([[0,0.04,0.19,0.2,0.17//,37,40]]) #['Target on test data: Acetone 1 ppm\\n [Logs]: ']\n",
    "#test_x=np.array([[0,float(e0.get()),float(e1.get()),float(e2.get()),float(e3.get()),float(e4.get()),float(e5.get())]])\n",
    "df_test = pd.DataFrame(data=test_x, index=[0], columns=[ \"TGS 826\", \"TGS 822\", \"TGS 2600\", \"TGS 2602\", \"Temperature\", \"Humidity\"])\n",
    "#print(df_test)\n",
    "predict_test = model.predict(df_test)\n",
    "print('\\nTarget on test data',predict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TGS 826</th>\n",
       "      <th>TGS 822</th>\n",
       "      <th>TGS 2600</th>\n",
       "      <th>TGS 2602</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.31</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.30</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.29</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.28</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9147</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6624 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TGS 826  TGS 822  TGS 2600  TGS 2602  Temperature  Humidity\n",
       "0        0.06     0.24      0.23      0.32         38.0      42.0\n",
       "1        0.06     0.24      0.23      0.31         38.0      42.0\n",
       "2        0.06     0.24      0.23      0.30         38.0      42.0\n",
       "3        0.06     0.24      0.23      0.29         38.0      42.0\n",
       "4        0.05     0.24      0.23      0.28         38.0      42.0\n",
       "...       ...      ...       ...       ...          ...       ...\n",
       "9146     0.04     0.17      0.20      0.16         37.0      39.0\n",
       "9147     0.04     0.17      0.20      0.16         37.0      39.0\n",
       "9148     0.04     0.17      0.20      0.17         37.0      39.0\n",
       "9149     0.04     0.17      0.20      0.17         37.0      39.0\n",
       "9150     0.04     0.17      0.20      0.17         37.0      39.0\n",
       "\n",
       "[6624 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x #after removing ID cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "<class 'numpy.ndarray'>\n",
      "[1.4371931e-04 4.4605717e-05 2.6317524e-05 6.9275840e-05 5.1633269e-05\n",
      " 3.9121780e-05 4.8365814e-04 4.9716353e-05 4.7688340e-05 9.9403375e-01\n",
      " 2.5356669e-05 4.9835693e-05 2.5862999e-05 2.8224825e-04 4.6272068e-03]\n",
      "14 9 14\n",
      "Ammonia 5 ppm, Confidence(Prob): 0.9940337538719177\n"
     ]
    }
   ],
   "source": [
    "#version3.0\n",
    "\n",
    "model = XGBClassifier()\n",
    " \n",
    "# fit the model with the training data\n",
    "# model.fit(X_train,y_train)#train_x,train_y\n",
    "model.fit(train_x,train_y)\n",
    "#print(\"Predictions through input entries\")\n",
    "# test_x=np.array([[0.04,0.19,0.2,0.17,37,40]]) #['Target on test data: Acetone 1 ppm\\n [Logs]: ']\n",
    "'''\n",
    "0.04,0.17,0.2,0.17,37,39\n",
    "0.06,0.16,0.19,0.2,34,38\n",
    "0.12,0.33,0.26,0.69,39,29\n",
    "0.04,0.13,0.17,0.17,36,37\n",
    "\n",
    "\n",
    "'''\n",
    "test_x=np.array([[0.04,0.17,0.2,0.17]]) #['Target on test data: Ammonia 5 ppm\\n [Logs]: ']\n",
    "#test_x=np.array([[0,float(e0.get()),float(e1.get()),float(e2.get()),float(e3.get()),float(e4.get()),float(e5.get())]])\n",
    "df_test = pd.DataFrame(data=test_x, index=[0], columns=[\"TGS 826\", \"TGS 822\", \"TGS 2600\", \"TGS 2602\"])\n",
    "#df_test = pd.DataFrame(data=test_x, index=[0], columns=[\"TGS 826\", \"TGS 822\", \"TGS 2600\", \"TGS 2602\", \"Temperature\", \"Humidity\"])\n",
    "#print(df_test)\n",
    "predict_test = model.predict(df_test)\n",
    "# print('\\nTarget on test data',predict_test)\n",
    "p2=model.predict_proba(df_test)\n",
    "# print('\\nTarget on test data(p2)',p2)\n",
    "print(type(p2[0]))\n",
    "# print(p2[0]/10e-1)\n",
    "# print(np.divide(p2[0],10e-1))#true_divide\n",
    "# print(float(p2[0]))\n",
    "#print(p2[0][0])\n",
    "# print(p2[0].argmax())\n",
    "oldprobs=p2[0]\n",
    "probs=p2[0]\n",
    "print(probs)\n",
    "#print(float(probs))\n",
    "# x = np.arange(probs)\n",
    "# convertedArray = x.astype(np.float)#np.int\n",
    "# print(convertedArray)\n",
    "\n",
    "#first=p2[0].argmax()\n",
    "#print(np.sort(probs))\n",
    "first=probs.argmax()\n",
    "# probs=np.delete(probs, first)\n",
    "temp=probs[first]\n",
    "probs[first]=-100e-10 #-100\n",
    "second=probs.argmax()\n",
    "probs[first]=temp\n",
    "# print(p2[0][first],p2[0][second])\n",
    "#print(probs[first],probs[second])\n",
    "\n",
    "'''class_dict={\n",
    "    0: \"Acetone 1 ppm\",\n",
    "    1: \"Acetone 1 ppm\"\n",
    "}....'''\n",
    "classes = train_data['Class']  #train_data.drop(columns=['<all_other_than_\"Class\">'],axis=1)\n",
    "classes=classes.drop_duplicates(keep='first', inplace=False)\n",
    "classesOld=classes\n",
    "#print(classes)\n",
    "# print(classes.iloc[first])\n",
    "# print(first, second)\n",
    "# if first+1 == second:\n",
    "#     range_res=f'{classes.iloc[first]} to {classes.iloc[second]}'\n",
    "# else:\n",
    "#     range_res=f'{classes.iloc[first]}'\n",
    "\n",
    "# print(range_res)\n",
    "\n",
    "#print(predict_test[0], classes.iloc[first], classes.iloc[second])\n",
    "#print(type(classes))\n",
    "#print(classes.index[classes['Class'] == predict_test[0]].tolist()) #for dataframes\n",
    "# print(classes[classes == predict_test[0]])\n",
    "res=classes[classes == predict_test[0]]\n",
    "#print(type(res))\n",
    "# type(res.iloc[0])\n",
    "\n",
    "# print(classes['Class'])\n",
    "\n",
    "classes=pd.DataFrame(classes) #classes.to_frame(index_col=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]) #\n",
    "classes['id']=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "classes\n",
    "# indexId=classes.index[classes['Class'] == predict_test[0]].tolist()[0] #for dataframes\n",
    "# # classes.iloc[int(indexId)]\n",
    "# inde = int(classes[classes['Class']==predict_test[0]].index[0])\n",
    "# inde\n",
    "# inde2 = classes[classes['Class']==predict_test[0]].index.values.astype(int)[0]\n",
    "# inde\n",
    "# print(classes[classes['Class']==predict_test[0]].index.values)\n",
    "# # classes.loc([predict_test[0]])\n",
    "# print(classes[classes['Class']==predict_test[0]].id.values[0])\n",
    "idOfPredClass=classes[classes['Class']==predict_test[0]].id.values[0]\n",
    "idOfPredClass, first, second\n",
    "print(idOfPredClass, first, second)\n",
    "\n",
    "'''\n",
    "0-4 --> Acetone  diff=0->4 or can create ranges conditions (f>0 && f<=4 ..)\n",
    "5-9 --> Ethanol  diff=0->4\n",
    "10-14 --> Ammonia diff=0->4\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "    #examples testing\n",
    "    # first=1\n",
    "    # second=12\n",
    "    # idOfPredClass=11\n",
    "    # print(idOfPredClass, first, second)\n",
    "    # print(classesOld.iloc[idOfPredClass], classesOld.iloc[first], classesOld.iloc[second])\n",
    "    # predict_test[0]=classesOld.iloc[idOfPredClass]\n",
    "    #examples testing\n",
    "\n",
    "'''\n",
    "\n",
    "#print(idOfPredClass, first, second)\n",
    "\n",
    "diffx=first-idOfPredClass #abs()\n",
    "diffy=second-idOfPredClass #abs()\n",
    "#print(diffx, diffy)\n",
    "cbucPpred=checkbucket(idOfPredClass)\n",
    "cbucFirst=checkbucket(first)\n",
    "cbucSecond=checkbucket(second)\n",
    "# print(cbucPpred==cbucFirst)\n",
    "#print(checkPercentageConf(probs,first))\n",
    "# print(p2,first)\n",
    "if diffx<=4 and diffx>=0 and cbucPpred==cbucFirst and checkPercentageConf(oldprobs,first):\n",
    "    #print(1)\n",
    "    if idOfPredClass+1 == first and idOfPredClass+1<15:\n",
    "        range_res=f'{predict_test[0]} to {classesOld.iloc[first]}' + f', Confidence(Prob): {oldprobs[first]}'\n",
    "    else:\n",
    "        range_res=f'{predict_test[0]}'+ f', Confidence(Prob): {oldprobs[first]}'\n",
    "elif diffy<=4 and diffy>=0 and cbucPpred==cbucSecond and checkPercentageConf(oldprobs,second):\n",
    "    #print(11)\n",
    "    if idOfPredClass+1 == second and idOfPredClass+1<15:\n",
    "        range_res=f'{predict_test[0]} to {classesOld.iloc[second]}' + f', Confidence(Prob): {oldprobs[first]}'\n",
    "    else:\n",
    "        range_res=f'{predict_test[0]}'+ f', Confidence(Prob): {oldprobs[first]}'\n",
    "else:\n",
    "#     print(111)\n",
    "    range_res=f'{predict_test[0]}' + f', Confidence(Prob): {oldprobs[first]}'\n",
    "    \n",
    "        \n",
    "print(range_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.82039876e-04/10e-1\n",
    "9.98515666e-01/10e-1\n",
    "float(9.98515666e-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TGS 826</th>\n",
       "      <th>TGS 822</th>\n",
       "      <th>TGS 2600</th>\n",
       "      <th>TGS 2602</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9147</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6624 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TGS 826  TGS 822  TGS 2600  TGS 2602\n",
       "0        0.06     0.24      0.23      0.32\n",
       "1        0.06     0.24      0.23      0.31\n",
       "2        0.06     0.24      0.23      0.30\n",
       "3        0.06     0.24      0.23      0.29\n",
       "4        0.05     0.24      0.23      0.28\n",
       "...       ...      ...       ...       ...\n",
       "9146     0.04     0.17      0.20      0.16\n",
       "9147     0.04     0.17      0.20      0.16\n",
       "9148     0.04     0.17      0.20      0.17\n",
       "9149     0.04     0.17      0.20      0.17\n",
       "9150     0.04     0.17      0.20      0.17\n",
       "\n",
       "[6624 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x\n",
    "train_y\n",
    "train_x\n",
    "# test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:49:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Predictions through CSV file\n",
      "Shape of testing data after dropping : (6624, 8)\n",
      "[0.9758532  0.99144614 0.99470574 ... 0.99403375 0.99403375 0.99403375]\n",
      "[WinError 183] Cannot create a file when that file already exists: 'logs'\n"
     ]
    }
   ],
   "source": [
    "#version3\n",
    "model = XGBClassifier()\n",
    " \n",
    "# fit the model with the training data\n",
    "#model.fit(X_train,y_train)#train_x,train_y\n",
    "model.fit(train_x,train_y)\n",
    "print(\"Predictions through CSV file\")\n",
    "# print(label_file_explorer.cget(\"text\"))\n",
    "test_data = pd.read_csv('R:/airprob/datasets/Data Sheet - Buvana - Trial 1.csv')#label_file_explorer.cget(\"text\")\n",
    "test_data=test_data.dropna(subset=['TGS 826', 'TGS 822', 'TGS 2600', 'TGS 2602', 'Temperature', 'Humidity', 'Class'])\n",
    "#df_test = pd.DataFrame(data=test_x, index=[0], columns=[\"TGS 826\", \"TGS 822\", \"TGS 2600\", \"TGS 2602\"])\n",
    "print('Shape of testing data after dropping :',train_data.shape)\n",
    "# seperate the independent and target variable on training data\n",
    "#test_data_x = test_data.drop(columns=['Class', 'ID'],axis=1)\n",
    "test_data_x = test_data.drop(columns=['Class','Temperature', 'Humidity', 'ID'],axis=1)\n",
    "test_data_y = test_data['Class']\n",
    "predict_test = model.predict(test_data_x)\n",
    "#print('\\nTarget on test data',predict_test)\n",
    "p2=model.predict_proba(test_data_x)#version2 needs conf,probs of each class(out of 15) to the input features,args and present range(highest,second highest)\n",
    "#print('\\nTarget on test data(p2)',p2)\n",
    "output= \" \\n \" + \"[Logs]: \" + 'Target on test data(Range): '+ predict_test + \" \\n \"\n",
    "# print(type(predict_test))\n",
    "#print(predict_test)\n",
    "# convert n_array into dataframe\n",
    "\n",
    "result=[]\n",
    "conf=[]\n",
    "for idx, i in enumerate(p2):#p2[200:300],[0,50] #for index, element in zip(range(0,countries),countries): , or using cnt,cnt++\n",
    "    #print(i)\n",
    "    oldprobs=i\n",
    "    probs=i\n",
    "    #print(probs)\n",
    "    #first=p2[0].argmax()\n",
    "    first=probs.argmax()\n",
    "    # probs=np.delete(probs, first)\n",
    "    temp=probs[first]\n",
    "    probs[first]=-100e-10 #-100\n",
    "    second=probs.argmax()\n",
    "    probs[first]=temp\n",
    "    #print(first, second)\n",
    "    # '''class_dict={\n",
    "    #     0: \"Acetone 1 ppm\",\n",
    "    #     1: \"Acetone 1 ppm\"\n",
    "    # }....'''\n",
    "    # classes = train_data['Class']\n",
    "    # classes=classes.drop_duplicates(keep='first', inplace=False)\n",
    "    # #print(classes.iloc[first])\n",
    "    # if first+1 == second:\n",
    "    #         range_res=f'{classes.iloc[first]} to {classes.iloc[second]}'\n",
    "    # else:\n",
    "    #         range_res=f'{classes.iloc[first]}'\n",
    "    # res.append(range_res)\n",
    "\n",
    "    ## v3 ##\n",
    "    classes = train_data['Class']  #train_data.drop(columns=['<all_other_than_\"Class\">'],axis=1)\n",
    "    classes=classes.drop_duplicates(keep='first', inplace=False)\n",
    "    classesOld=classes\n",
    "    #print(predict_test[idx], classes.iloc[first], classes.iloc[second])\n",
    "    #print(predict_test[idx])\n",
    "    res=classes[classes == predict_test[idx]]\n",
    "    classes=pd.DataFrame(classes) #classes.to_frame(index_col=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]) # #classes=classes = pd.DataFrame(classes)\n",
    "    classes['id']=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "    #print(classes)\n",
    "    \n",
    "    idOfPredClass=classes[classes['Class']==predict_test[idx]].id.values[0]\n",
    "#     #idOfPredClass, first, second\n",
    "#     # print(idOfPredClass, first, second)\n",
    "#     '''\n",
    "#     0-4 --> Acetone  diff=0->4 or can create ranges conditions (f>0 && f<=4 ..)\n",
    "#     5-9 --> Ethanol  diff=0->4\n",
    "#     10-14 --> Ammonia diff=0->4\n",
    "#     '''\n",
    "\n",
    "#     '''\n",
    "\n",
    "#         #examples testing\n",
    "#         # first=1\n",
    "#         # second=12\n",
    "#         # idOfPredClass=11\n",
    "#         # print(idOfPredClass, first, second)\n",
    "#         # print(classesOld.iloc[idOfPredClass], classesOld.iloc[first], classesOld.iloc[second])\n",
    "#         # predict_test[0]=classesOld.iloc[idOfPredClass]\n",
    "#         #examples testing\n",
    "\n",
    "#     '''\n",
    "\n",
    "    diffx=first-idOfPredClass #abs()\n",
    "    diffy=second-idOfPredClass #abs()\n",
    "    #print(diffx, diffy)\n",
    "    #print(idOfPredClass, first, second)\n",
    "    cbucPpred=checkbucket(idOfPredClass)\n",
    "    cbucFirst=checkbucket(first)\n",
    "    cbucSecond=checkbucket(second)\n",
    "    if diffx<=4 and diffx>=0 and cbucPpred==cbucFirst and checkPercentageConf(oldprobs,first):\n",
    "        #print(1)\n",
    "        if idOfPredClass+1 == first and idOfPredClass+1<15:\n",
    "            range_res=f'{predict_test[idx]} to {classesOld.iloc[first]}'\n",
    "        else:\n",
    "            range_res=f'{predict_test[idx]}'\n",
    "    elif diffy<=4 and diffy>=0 and cbucPpred==cbucSecond and checkPercentageConf(oldprobs,second):\n",
    "        #print(11)\n",
    "        if idOfPredClass+1 == second and idOfPredClass+1<15:\n",
    "            range_res=f'{predict_test[idx]} to {classesOld.iloc[second]}'\n",
    "        else:\n",
    "            range_res=f'{predict_test[idx]}'\n",
    "    else:\n",
    "    #     print(111)\n",
    "        range_res=f'{predict_test[idx]}'\n",
    "\n",
    "\n",
    "    #print(type(range_res))\n",
    "    result.append(range_res)\n",
    "    conf.append(oldprobs[first])\n",
    "\n",
    "\n",
    "\n",
    "# print(result)\n",
    "#print(len(result))#res\n",
    "#print(len(predict_test))\n",
    "n_res=np.array(result)#res\n",
    "n_conf=np.array(conf)#conf\n",
    "#type(n_res)\n",
    "#type(predict_test)\n",
    "#print(n_res)\n",
    "#print(n_conf)\n",
    "DF = pd.DataFrame({'Predicted_Class:':n_res,'Confidence(Prob): ':n_conf})#predict_test\n",
    "# DF = pd.DataFrame(n_res)#predict_test\n",
    "dtime=str(datetime.datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")).replace(\" \", \"_\")\n",
    "#os.mkdir(\"logs\")#path = os.path.join(parent_dir, directory), os.mkdir(path, mode) \n",
    "#'''\n",
    "\n",
    "'''\n",
    "        path=\"logs\"\n",
    "        path.exists()\n",
    "        path.isfile() \n",
    "        path.isdir() \n",
    "        pathlib.Path.exists()\n",
    "        isFile = os.path.isfile(path) \n",
    "        isdir = os.path.isdir(path)\n",
    "        isExist = os.path.exists(path) \n",
    "        print(isExist)\n",
    "        print(isdir) \n",
    "        print(isFile)\n",
    "\n",
    "        # Python program to explain os.path.isdir() method  \n",
    "      \n",
    "        # importing os.path module  \n",
    "        import os.path \n",
    "            \n",
    "            \n",
    "        # Create a directory \n",
    "        # (in current working directory) \n",
    "        dirname = \"GeeksForGeeks\"\n",
    "        os.mkdir(dirname) \n",
    "            \n",
    "        # Create a symbolic link \n",
    "        # pointing to above directory \n",
    "        symlink_path = \"D:/Pycharm projects/GeeksforGeeks/Nikhil/\"\n",
    "        os.symlink(dirname, symlink_path) \n",
    "            \n",
    "            \n",
    "        path = dirname \n",
    "            \n",
    "        # Now, Check whether the  \n",
    "        # specified path is an \n",
    "        # existing directory or not \n",
    "        isdir = os.path.isdir(path) \n",
    "        print(isdir) \n",
    "            \n",
    "        path = symlink_path \n",
    "            \n",
    "        # Check whether the  \n",
    "        # specified path (which is a \n",
    "        # symbolic link ) is an \n",
    "        # existing directory or not \n",
    "        isdir = os.path.isdir(path) \n",
    "        print(isdir)\n",
    "\n",
    "        '''\n",
    "\n",
    "try: #if already exist then exception raise(can be done with conditions(if..else) check already present, if not create or using try..catch block)\n",
    "    os.mkdir(\"logs\") #path\n",
    "except OSError as error: \n",
    "    print(error)  \n",
    "#'''\n",
    "filename=f\"./logs/testing_data_logs_{dtime}.csv\"#str()#.\\logs\\ # log files also can be added to input entries\n",
    "#print(filename)\n",
    "#print(type(filename))\n",
    "#DF.to_csv(str(filename))\n",
    "DF.to_csv(str(filename),mode = 'w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"trainning_data_air_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkbucket(n):\n",
    "    if n>=0 and n<=4: \n",
    "        return 0\n",
    "    elif n>=5 and n<=9: \n",
    "        return 1\n",
    "    elif n>=10 and n<=14:\n",
    "        return 2\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkbucket(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.array([1.71404863e-05, 2.79902568e-04, 1.48398540e-05, 3.42651037e-05,\n",
    " 6.36910627e-05, 6.03165063e-05, 1.82039876e-04, 3.47217196e-04,\n",
    " 3.21080675e-04, 6.75599149e-05, 6.46988046e-05, 1.28511538e-05,\n",
    " 9.98515666e-01, 5.75446666e-06, 1.29931195e-05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000017, 0.000280, 0.000015, 0.000034, 0.000064, 0.000060,\n",
       "       0.000182, 0.000347, 0.000321, 0.000068, 0.000065, 0.000013,\n",
       "       0.998516, 0.000006, 0.000013])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000017 0.000280 0.000015 0.000034 0.000064 0.000060 0.000182 0.000347\n",
      " 0.000321 0.000068 0.000065 0.000013 0.998516 0.000006 0.000013]\n"
     ]
    }
   ],
   "source": [
    "# x = np.arange(p)\n",
    "# x\n",
    "float_array = p.astype(np.float)\n",
    "print(float_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.71404863e-05, 2.79902568e-04, 1.48398540e-05, 3.42651037e-05,\n",
       "       6.36910627e-05, 6.03165063e-05, 1.82039876e-04, 3.47217196e-04,\n",
       "       3.21080675e-04, 6.75599149e-05, 6.46988046e-05, 1.28511538e-05,\n",
       "       9.98515666e-01, 5.75446666e-06, 1.29931195e-05])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array(p)\n",
    "x=np.asfarray(x,float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000017, 0.000280, 0.000015, 0.000034, 0.000064, 0.000060,\n",
       "       0.000182, 0.000347, 0.000321, 0.000068, 0.000065, 0.000013,\n",
       "       0.998516, 0.000006, 0.000013], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.format_float_scientific(np.float32(x))\n",
    "np.float32(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.71404863e-05\n",
      "0.000279902568\n",
      "1.4839854e-05\n",
      "3.42651037e-05\n",
      "6.36910627e-05\n",
      "6.03165063e-05\n",
      "0.000182039876\n",
      "0.000347217196\n",
      "0.000321080675\n",
      "6.75599149e-05\n",
      "6.46988046e-05\n",
      "1.28511538e-05\n",
      "0.998515666\n",
      "5.75446666e-06\n",
      "1.29931195e-05\n"
     ]
    }
   ],
   "source": [
    "for i in x:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998515666\n"
     ]
    }
   ],
   "source": [
    "for i in x:\n",
    "    if i>=0.75:\n",
    "     print(float(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.71404863e-05\n",
      "0.000279902568\n",
      "1.4839854e-05\n",
      "3.42651037e-05\n",
      "6.36910627e-05\n",
      "6.03165063e-05\n",
      "0.000182039876\n",
      "0.000347217196\n",
      "0.000321080675\n",
      "6.75599149e-05\n",
      "6.46988046e-05\n",
      "1.28511538e-05\n",
      "0.998515666\n",
      "5.75446666e-06\n",
      "1.29931195e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.000017, 0.000280, 0.000015, 0.000034, 0.000064, 0.000060,\n",
       "       0.000182, 0.000347, 0.000321, 0.000068, 0.000065, 0.000013,\n",
       "       0.998516, 0.000006, 0.000013])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx,i in enumerate(x):\n",
    "    x[idx]=float(i)\n",
    "    print(i)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000017, 0.000280, 0.000015, 0.000034, 0.000064, 0.000060,\n",
       "       0.000182, 0.000347, 0.000321, 0.000068, 0.000065, 0.000013,\n",
       "       0.998516, 0.000006, 0.000013])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-a766705f146d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'first' is not defined"
     ]
    }
   ],
   "source": [
    "x[first]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "#numpy.set_printoptions(precision=2)\n",
    "#numpy.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000017, 0.000280, 0.000015, 0.000034, 0.000064, 0.000060,\n",
       "       0.000182, 0.000347, 0.000321, 0.000068, 0.000065, 0.000013,\n",
       "       0.998516, 0.000006, 0.000013])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000017, 0.000280, 0.000015, 0.000034, 0.000064, 0.000060,\n",
       "       0.000182, 0.000347, 0.000321, 0.000068, 0.000065, 0.000013,\n",
       "       0.998516, 0.000006, 0.000013])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ec0817c4de42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'{:f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# x = [float(item) for item in x]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x = ['{:f}'.format(item) for item in x]\n",
    "# x = [float(item) for item in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-96027f586eb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#np.savetxt('temp.txt', x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#np.savetxt('temp2.txt', x, fmt='%f')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x\n",
    "#np.savetxt('temp.txt', x)\n",
    "#np.savetxt('temp2.txt', x, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d12e5f833ea1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "if float(x[first])>=0.75:\n",
    "    print(float(x[first]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(float(x[first]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print map(lambda x: \"{0:.16f}\".format(x), a)\n",
    "# map(\"{0:.16f}\".format, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPercentageConf(x,val):\n",
    "    #x = ['{:f}'.format(item) for item in x]\n",
    "    #print(x)\n",
    "    #if float(x[val])>=0.75:\n",
    "    if x[val]>=0.75:#threshold\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-427223b65544>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcheckPercentageConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#(<prob>,<first or second>)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "checkPercentageConf(x,12)#(<prob>,<first or second>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.71404863e-05, 2.79902568e-04, 1.48398540e-05, 3.42651037e-05,\n",
       "       6.36910627e-05, 6.03165063e-05, 1.82039876e-04, 3.47217196e-04,\n",
       "       3.21080675e-04, 6.75599149e-05, 6.46988046e-05, 1.28511538e-05,\n",
       "       9.98515666e-01, 5.75446666e-06, 1.29931195e-05])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
